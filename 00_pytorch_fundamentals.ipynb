{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIg5wKtW1puqCyvRWy2dCm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayanarajasekhar/PyTorch/blob/main/00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 00. PyTorch Fundamentals\n",
        "\n",
        "### What is PyTorch ?\n",
        "[PyTorch](https://pytorch.org/) is an open source machine learning and deep learning framework.\n",
        "\n",
        "### What can PyTorch be used for ?\n",
        "PyTorch allows you to manipulate and process data and write machine learning algorithms using Python code.\n",
        "\n"
      ],
      "metadata": {
        "id": "PsCFKZjftxQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1n6PyuOtwwu",
        "outputId": "8750006d-5c8b-4cdf-960a-cd32203385ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intoduction to tensors\n",
        "\n",
        "Tensors are the fundamental building blocks of machine learning.\n",
        "\n",
        "Their job is to represent data in a numerical way.\n",
        "\n",
        "For Example, you could represent an image as a tensor with shape ```[3, 224, 224]``` which would mean ```[color_channels, height, width]```"
      ],
      "metadata": {
        "id": "5zCZeHVmvSck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating tensors\n",
        "> Documentaion on [tensers](https://docs.pytorch.org/docs/stable/tensors.html)\n",
        "\n",
        "Lets create a **scalar**\n",
        "\n",
        "### Scalar\n",
        "A scalar is a single number and in tensor-speak it's a zero dimension tensor"
      ],
      "metadata": {
        "id": "sCfGdnViwCTE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmSrcaA5tFmn",
        "outputId": "8a486f3f-0c77-4be3-f1d9-8fd6d5b47d1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means although  ```scalar``` is a single number, its of type ```torch.tensor```\n",
        "\n",
        "Lets check te dimensions of a tensor using ```ndim``` attribute"
      ],
      "metadata": {
        "id": "w7TDStzfy_iR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDqYS26dy8jI",
        "outputId": "a716898b-bf7d-4243-b2b8-bbce0ec92db6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if we want to retriece the number from the tensor ?\n",
        "\n",
        "As in, turn it from  ```torch.tensor``` to a python integer?\n",
        "\n",
        "To do we can use ```item()``` method\n"
      ],
      "metadata": {
        "id": "_VwULIIcza4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the python number within a tensor (Only works with one-element tensors)\n",
        "scalar.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZqoqvL1zyI1",
        "outputId": "b1447d40-3a7f-4154-c208-b8225d7760e0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector\n",
        "\n",
        "A vector is a single dimension tensor but can contain many numbers.\n",
        "\n",
        "As in, you can have a vector ```[3, 2]``` to describe ```[bedrooms, bathrooms]``` in a house. Or you could have ```[3, 2, 2]``` to describe ```[bedrooms, bathrooms, car_parks]``` in a house.\n",
        "\n",
        "The important trend here is that a vector is flexible in what it can reporesent"
      ],
      "metadata": {
        "id": "yMNBAmESz-e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector\n",
        "vector = torch.tensor([7, 7])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2n5o5Uwz-Ok",
        "outputId": "1e119c43-a22c-4b71-95d9-7799796b209a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check number of dimensions of vector\n",
        "vector.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62XoIpEf01Lg",
        "outputId": "c2fac174-2a3a-49fe-d355-ce0288e7211c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "89vt32ro1vDH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping, View, Stacking, Squeezing and Unsqueezing, Permute tensors\n",
        "\n",
        "* Reshaping - Reshape an input tensor to a defined shape. (Reshape should be compatable with original tensor size)\n",
        "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor (Tensor Reference). (View should be compatable with original tensor size)\n",
        "* Stacking - Concatenate a sequence of tensors along a new dimension. Combine multipe tensors on top of each other (stack, vstack - verical stack or hstack - horizental stack).\n",
        "* Squeeze - Remove `1` dimension from a tensor.\n",
        "* Unsqueezing - Addd `1` dimension to a target tensor.\n",
        "* Permute - Return a view of input with dimensions permuted (swapped) in a certain way."
      ],
      "metadata": {
        "id": "Qv15Xm5yx4P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a tensor\n",
        "import torch\n",
        "x = torch.arange(1., 10,)\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk63YS2Ix34c",
        "outputId": "14a810d2-e094-4968-fcce-37b8aa9edf55"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra dimension\n",
        "x_reshaped = x.reshape(1, 7) # we are trying to squze 9 element tensor to 7 elements\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "kxDdmZgAz5rJ",
        "outputId": "9b666467-e3f5-4d12-a36d-fd9d1eb2a2f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[1, 7]' is invalid for input of size 9",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1645377546.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Add an extra dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_reshaped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 7]' is invalid for input of size 9"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_reshaped = x.reshape(1, 9) # we are matching elements with x tensor elements\n",
        "x_reshaped, x_reshaped.shape # Obsesrve the change in tensor shape from [9] -> [1, 9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJwbxbug0Itu",
        "outputId": "d4d59afe-28be-42c7-d259-2311d64f3853"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_reshaped = x.reshape(2, 9) # we are trying to reshape 2 * 9 elements when x has only 9 elements\n",
        "x_reshaped, x_reshaped.shape # Obsesrve the change in tensor shape from [9] -> [1, 9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "jrWazl370mGb",
        "outputId": "241cefc1-c163-46bc-814b-e1c59759dea2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[2, 9]' is invalid for input of size 9",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-96482055.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we are matching elements with x tensor elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_reshaped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;31m# Obsesrve the change in tensor shape from [9] -> [1, 9]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 9]' is invalid for input of size 9"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_reshaped = x.reshape(9, 1)\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Scw6kGX1ILX",
        "outputId": "6dff01f3-6d2b-4461-8b5d-3fa068ef005d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.],\n",
              "         [2.],\n",
              "         [3.],\n",
              "         [4.],\n",
              "         [5.],\n",
              "         [6.],\n",
              "         [7.],\n",
              "         [8.],\n",
              "         [9.]]),\n",
              " torch.Size([9, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(1., 11.) # now x has 10 elements\n",
        "x_reshaped = x.reshape(5, 2) # this will work since 5 * 2 = 10 which is equal to the elements in original tensor\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9mGgdMy1xZp",
        "outputId": "81dc9547-99e2-4d25-d9a0-06bc9276d35f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1.,  2.],\n",
              "         [ 3.,  4.],\n",
              "         [ 5.,  6.],\n",
              "         [ 7.,  8.],\n",
              "         [ 9., 10.]]),\n",
              " torch.Size([5, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the view\n",
        "x = torch.arange(1., 10.)\n",
        "z = x.view(3, 3) # Even view should match elements in original tensor\n",
        "x, x.shape, z, z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDqi59N81YxM",
        "outputId": "1d643510-b27f-49b4-86cc-b54ed1c3c355"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
              " torch.Size([9]),\n",
              " tensor([[1., 2., 3.],\n",
              "         [4., 5., 6.],\n",
              "         [7., 8., 9.]]),\n",
              " torch.Size([3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z[0][0] = 5\n",
        "x, z # Since z is a reference tensor, changes made to view will reflect in original tensor as well"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybbBw1uk2mUT",
        "outputId": "13395d8b-88c8-4111-8e93-61a2515308dd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
              " tensor([[5., 2., 3.],\n",
              "         [4., 5., 6.],\n",
              "         [7., 8., 9.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack tensors on top of each other\n",
        "y = torch.stack([x, x, x, x], dim=0)\n",
        "z = torch.vstack([x, x, x, x])\n",
        "y, z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg3XBW8r3vAF",
        "outputId": "a3c0d84a-ed83-46ac-c991-3b6a0a1741bb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "         [5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
              " tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "         [5., 2., 3., 4., 5., 6., 7., 8., 9.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.stack([x, x, x, x], dim=1)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyswwMG84Ejl",
        "outputId": "4d4312be-5926-4e40-bfa1-66decafd57d3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 5., 5., 5.],\n",
              "        [2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3.],\n",
              "        [4., 4., 4., 4.],\n",
              "        [5., 5., 5., 5.],\n",
              "        [6., 6., 6., 6.],\n",
              "        [7., 7., 7., 7.],\n",
              "        [8., 8., 8., 8.],\n",
              "        [9., 9., 9., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.cat([x, x, x, x], dim= 0)\n",
        "z = torch.hstack([x, x, x, x])\n",
        "y, z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPt82_R_4IXf",
        "outputId": "583ef0b6-35c9-4049-b108-dba217f24f51"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5., 2., 3., 4., 5., 6., 7., 8., 9., 5., 2., 3., 4., 5., 6., 7., 8., 9.,\n",
              "         5., 2., 3., 4., 5., 6., 7., 8., 9., 5., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
              " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9., 5., 2., 3., 4., 5., 6., 7., 8., 9.,\n",
              "         5., 2., 3., 4., 5., 6., 7., 8., 9., 5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yLHKgdnY47YS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}